import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.datasets import imdb
from tensorflow.keras.preprocessing.sequence import pad_sequences

num_words = 10000
(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = num_words)
max_len = 200
x_train = pad_sequences(x_train, maxlen = max_len)
x_test = pad_sequences(x_test, maxlen = max_len)

model = Sequential([
	layers.Embedding(input_dim = num_words, output_dim = 32, input_length = max_len),
	layers.GlobalAveragePooling1D(),
	layers.Dense(16, activation = 'relu'),
	layers.Dense(1, activation = 'sigmoid')
])
model.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])

history = model.fit(x_train, y_train, epochs=10, batch_size = 512, validation_split = 0.2)

sample_review = x_test[1]
pred = model.predict(sample_review.reshape(1, -1))

print('Positive' if pred[0][0] > 0.5 else 'Negative')
